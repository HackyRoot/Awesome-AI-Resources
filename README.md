
# Awesome-AI-Resources

## Generative AI

### LLM

#### Run LLM on local machine:
  - Ollama: https://github.com/ollama/ollama/
  - LM Studio: https://lmstudio.ai/

#### Build LLM powered apps:
- LangChain: https://python.langchain.com/docs/get_started/introduction
- Open Source Drag and Drop customize LLM flow builder: https://github.com/FlowiseAI/Flowise
- Drag and Drop Langchain Flow Builder: https://github.com/logspace-ai/langflow
- Autonomous AI Agents in Browser: https://agentgpt.reworkd.ai/


#### Finetune LLM
- Finetune Llama 2 using ChatGPT: https://medium.com/@kshitiz.sahay26/how-i-created-an-instruction-dataset-using-gpt-3-5-to-fine-tune-llama-2-for-news-classification-ed02fe41c81f
- Finetune Llama 2 on Google Colab: https://www.datacamp.com/tutorial/fine-tuning-llama-2


#### RAG
- When to use: RAG is used when your use case with LLM is knowledge-intensive, you need to handle unclear questions and mitigate incorrect information. It helps ground LLM on the latest, verifiable information without constant retraining.
- What is RAG: https://research.ibm.com/blog/retrieval-augmented-generation-RAG
- Production RAG with Local models: https://www.youtube.com/watch?v=0zGHrcE-Zy4
- Local LLM with RAG: https://github.com/amscotti/local-LLM-with-RAG


#### Embeddings:
- What is Embedding: https://huggingface.co/blog/getting-started-with-embeddings
https://huggingface.co/sentence-transformers
- Tutorial - Embedding Generation with Sentence Transformer: https://towardsdatascience.com/easily-get-high-quality-embeddings-with-sentencetransformers-c61c0169864b
- Tutorial - Embedding Generation with Llama cpp: https://github.com/ggerganov/llama.cpp/tree/master/examples/embedding
